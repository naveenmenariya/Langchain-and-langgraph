{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d21e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Downloading llama_index-0.14.10-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting llama-index-llms-groq\n",
      "  Downloading llama_index_llms_groq-0.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting llama-index-embeddings-huggingface\n",
      "  Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl.metadata (458 bytes)\n",
      "Requirement already satisfied: python-dotenv in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (1.2.1)\n",
      "Collecting llama-index-cli<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_cli-0.5.3-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting llama-index-core<0.15.0,>=0.14.10 (from llama-index)\n",
      "  Downloading llama_index_core-0.14.10-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl.metadata (400 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-index-llms-openai<0.7,>=0.6.0 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.6.12-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting llama-index-readers-file<0.6,>=0.5.0 (from llama-index)\n",
      "  Downloading llama_index_readers_file-0.5.6-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-index-readers-llama-parse>=0.4.0 (from llama-index)\n",
      "  Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: nltk>3.8.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index) (3.9.2)\n",
      "Requirement already satisfied: aiohttp<4,>=3.8.6 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (3.13.2)\n",
      "Collecting aiosqlite (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading aiosqlite-0.22.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting banks<3,>=2.2.0 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading banks-2.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: dataclasses-json in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.3.1)\n",
      "Collecting dirtyjson<2,>=1.0.8 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filetype<2,>=1.2.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2025.10.0)\n",
      "Requirement already satisfied: httpx in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.28.1)\n",
      "Collecting llama-index-workflows!=2.9.0,<3,>=2 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading llama_index_workflows-2.11.6-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (3.6.1)\n",
      "Requirement already satisfied: numpy in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.3.5)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (12.0.0)\n",
      "Requirement already satisfied: platformdirs in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.5.1)\n",
      "Requirement already satisfied: pydantic>=2.8.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.12.5)\n",
      "Requirement already satisfied: pyyaml>=6.0.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (6.0.3)\n",
      "Requirement already satisfied: requests>=2.31.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=80.9.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (80.9.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.49 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.0.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (9.1.2)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.12.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.66.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (4.15.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (0.9.0)\n",
      "Requirement already satisfied: wrapt in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-core<0.15.0,>=0.14.10->llama-index) (2.0.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from aiohttp<4,>=3.8.6->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.22.0)\n",
      "Collecting griffe (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading griffe-1.15.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: jinja2 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.1.6)\n",
      "Requirement already satisfied: openai>=1.1.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (2.14.0)\n",
      "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.14.3)\n",
      "Requirement already satisfied: defusedxml>=0.7.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
      "Requirement already satisfied: pandas<3,>=2.0.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.3.3)\n",
      "Requirement already satisfied: pypdf<7,>=6.1.3 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (6.5.0)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.6,>=0.5.0->llama-index)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: soupsieve>=1.6.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.8.1)\n",
      "Collecting llama-index-instrumentation>=0.1.0 (from llama-index-workflows!=2.9.0,<3,>=2->llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (3.11)\n",
      "Requirement already satisfied: certifi in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from pydantic>=2.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (0.4.2)\n",
      "Collecting llama-index-llms-openai-like<0.6,>=0.5.0 (from llama-index-llms-groq)\n",
      "  Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: transformers<5,>=4.37.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (4.57.3)\n",
      "Requirement already satisfied: filelock in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (3.20.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.36.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (24.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (0.7.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers<5,>=4.37.0->llama-index-llms-openai-like<0.6,>=0.5.0->llama-index-llms-groq) (1.2.0)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-index-embeddings-huggingface) (5.2.0)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting llama-cloud==0.1.35 (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud-0.1.35-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting wrapt (from llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.88-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.88 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.88-py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: click<9,>=8.1.7 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from llama-cloud-services>=0.6.88->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (8.3.1)\n",
      "INFO: pip is looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.87-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.87 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.87-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.86-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.86 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.86-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.85-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: pip is still looking at multiple versions of llama-cloud-services to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting llama-cloud-services>=0.6.85 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.85-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.84-py3-none-any.whl.metadata (6.6 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting llama-cloud-services>=0.6.84 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.84-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.83-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.82 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.83-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.82-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.82-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.81-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.81 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.81-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.80-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.80 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.80-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.79-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.79 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.79-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.78-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.78 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.78-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.77-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.77 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.77-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.76-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.76 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.76-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.75-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.75 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.75-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.74-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.74 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.74-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.73-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.73 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.73-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.72-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.72 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.72-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.71-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.71 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.71-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.70-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.70 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.70-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.69-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.69 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.69-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.68-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.68 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.68-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.67-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.67 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.67-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.66-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.66 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.66-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.65-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.64 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.65-py3-none-any.whl.metadata (3.3 kB)\n",
      "  Downloading llama_cloud_services-0.6.64-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.64-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.63-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.63 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.63-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.62-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.62 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.62-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.60-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.60 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.60-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.59-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.59 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.59-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.58-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.58 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.58-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.57-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.56 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.57-py3-none-any.whl.metadata (3.7 kB)\n",
      "  Downloading llama_cloud_services-0.6.56-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.56-py3-none-any.whl.metadata (6.6 kB)\n",
      "  Downloading llama_parse-0.6.55-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.55 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.55-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting llama-parse>=0.5.0 (from llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_parse-0.6.54-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting llama-cloud-services>=0.6.54 (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index)\n",
      "  Downloading llama_cloud_services-0.6.54-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: joblib in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index) (1.5.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3,>=2.0.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (2.3.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.8.0)\n",
      "Requirement already satisfied: scipy in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.16.3)\n",
      "Requirement already satisfied: greenlet>=1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.3.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.14.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (1.1.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.26.2)\n",
      "Collecting colorama>=0.4 (from griffe->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from jinja2->banks<3,>=2.2.0->llama-index-core<0.15.0,>=0.14.10->llama-index) (3.0.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/naveen/Desktop/MyPython/venv/lib/python3.12/site-packages (from scikit-learn->sentence-transformers>=2.6.1->llama-index-embeddings-huggingface) (3.6.0)\n",
      "Downloading llama_index-0.14.10-py3-none-any.whl (7.5 kB)\n",
      "Downloading llama_index_cli-0.5.3-py3-none-any.whl (28 kB)\n",
      "Downloading llama_index_core-0.14.10-py3-none-any.whl (11.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.9/11.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading banks-2.2.0-py3-none-any.whl (29 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_embeddings_openai-0.5.1-py3-none-any.whl (7.0 kB)\n",
      "Downloading llama_index_llms_openai-0.6.12-py3-none-any.whl (26 kB)\n",
      "Downloading llama_index_readers_file-0.5.6-py3-none-any.whl (51 kB)\n",
      "Downloading llama_index_workflows-2.11.6-py3-none-any.whl (92 kB)\n",
      "Downloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_llms_groq-0.4.1-py3-none-any.whl (3.7 kB)\n",
      "Downloading llama_index_llms_openai_like-0.5.3-py3-none-any.whl (4.7 kB)\n",
      "Downloading llama_index_embeddings_huggingface-0.6.1-py3-none-any.whl (8.9 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.9.4-py3-none-any.whl (17 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading llama_cloud-0.1.35-py3-none-any.whl (303 kB)\n",
      "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
      "Downloading llama_index_instrumentation-0.4.2-py3-none-any.whl (15 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.5.1-py3-none-any.whl (3.2 kB)\n",
      "Downloading llama_parse-0.6.54-py3-none-any.whl (4.9 kB)\n",
      "Downloading llama_cloud_services-0.6.54-py3-none-any.whl (63 kB)\n",
      "Downloading aiosqlite-0.22.1-py3-none-any.whl (17 kB)\n",
      "Downloading griffe-1.15.0-py3-none-any.whl (150 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Installing collected packages: striprtf, dirtyjson, wrapt, colorama, aiosqlite, griffe, deprecated, llama-index-instrumentation, llama-cloud, banks, llama-index-workflows, llama-index-core, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-embeddings-huggingface, llama-cloud-services, llama-parse, llama-index-llms-openai-like, llama-index-cli, llama-index-readers-llama-parse, llama-index-llms-groq, llama-index\n",
      "\u001b[2K  Attempting uninstall: wrapt\n",
      "\u001b[2K    Found existing installation: wrapt 2.0.1\n",
      "\u001b[2K    Uninstalling wrapt-2.0.1:\n",
      "\u001b[2K      Successfully uninstalled wrapt-2.0.1\n",
      "\u001b[2K  Attempting uninstall: deprecatedm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/24\u001b[0m [griffe]\n",
      "\u001b[2K    Found existing installation: Deprecated 1.3.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/24\u001b[0m [deprecated]\n",
      "\u001b[2K    Uninstalling Deprecated-1.3.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/24\u001b[0m [deprecated]\n",
      "\u001b[2K      Successfully uninstalled Deprecated-1.3.1━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/24\u001b[0m [deprecated]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/24\u001b[0m [llama-index]\u001b[0m [llama-index-llms-openai-like]\n",
      "\u001b[1A\u001b[2KSuccessfully installed aiosqlite-0.22.1 banks-2.2.0 colorama-0.4.6 deprecated-1.2.18 dirtyjson-1.0.8 griffe-1.15.0 llama-cloud-0.1.35 llama-cloud-services-0.6.54 llama-index-0.14.10 llama-index-cli-0.5.3 llama-index-core-0.14.10 llama-index-embeddings-huggingface-0.6.1 llama-index-embeddings-openai-0.5.1 llama-index-indices-managed-llama-cloud-0.9.4 llama-index-instrumentation-0.4.2 llama-index-llms-groq-0.4.1 llama-index-llms-openai-0.6.12 llama-index-llms-openai-like-0.5.3 llama-index-readers-file-0.5.6 llama-index-readers-llama-parse-0.5.1 llama-index-workflows-2.11.6 llama-parse-0.6.54 striprtf-0.0.26 wrapt-1.17.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U llama-index llama-index-llms-groq python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0ad47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 22:26:31,897 - INFO - Load pretrained SentenceTransformer: BAAI/bge-small-en-v1.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 22:26:40,501 - INFO - 1 prompt is loaded, with the key: query\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a65fd547a1d4897b020f29fb401b687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab02e7ec5774befbd68210e156658c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-27 22:26:41,891 - INFO - HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The documents outline the rules and policy for employee leave, stating that employees are entitled to 20 days of annual leave with certain conditions for approval and usage.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, Settings\n",
    "from llama_index.llms.groq import Groq\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "# 1. Initialize Groq LLM with a current model\n",
    "\n",
    "llm = Groq(\n",
    "    model=\"llama-3.3-70b-versatile\",  # Updated model\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "\n",
    "# 2. Initialize Local Embedding Model\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
    ")\n",
    "\n",
    "\n",
    "# 3. Set Global Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "\n",
    "# 4. Load Documents\n",
    "\n",
    "# Create a folder named \"data\" and add .txt / .pdf files\n",
    "documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "\n",
    "\n",
    "# 5. Create Index\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "\n",
    "# 6. Query the Index\n",
    "\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "response = query_engine.query(\n",
    "    \"Summarize the documents in one sentence\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
